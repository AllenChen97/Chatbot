{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-04966e899546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdr_wx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/opt/jupyter-notebook/DingdingPush/Data_Validation/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'2020_10_24_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'wx_pfm.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_pfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mexcel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdr_pfm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "#冷启动：补充备用代码\n",
    "url_pfm = 'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!9500!!552e!!7ba1!!7406!!90e8!!2f!!ff08!!96c6!!56e2!!ff09!!4e1a!!52a1!!7cfb!!4e0b!!5355!!4e1a!!7ee9!!53ca!!8fdb!!5ea6!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=excel'\n",
    "url_wx = 'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!7eff!!7626!!5546!!57ce!!2f!!4f01!!4e1a!!5fae!!4fe1!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!!2f!!5546!!57ce!!28!!4f01!!4e1a!!5fae!!4fe1!!29!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=excel'\n",
    "dr_pfm = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + '2020_10_24_' + 'daily_pfm.xlsx'\n",
    "dr_wx = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + '2020_10_24_' + 'wx_pfm.xlsx'\n",
    "\n",
    "response = urllib.request.urlopen(url_pfm)\n",
    "excel = response.read()\n",
    "with open(dr_pfm,'wb') as f:\n",
    "    f.write(excel)                            #下载\n",
    "\n",
    "response = urllib.request.urlopen(url_wx)\n",
    "excel = response.read()\n",
    "with open(dr_wx,'wb') as f:\n",
    "    f.write(excel)                            #下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-11-12 17:26:29 ]: 任务一和二 报表间横向对比执行 成功\n",
      "[ 2020-11-12 17:26:30 ]: 任务三 没有渠道号的微信查询 成功\n",
      "[ 2020-11-12 17:26:46 ]: 任务四和五 定义机器人和上传图片 成功\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "######################################################################\n",
    "# Project Name: 企微推送数据检测\n",
    "# Job Name    : 每天早上9.40推送\n",
    "# Task Name   : wx_pfm_Data_Validation\n",
    "# Author      : CJZ\n",
    "# Create Date : 2020-10-21\n",
    "# Description : 《商城（企业微信）每日业绩报表_全部》\n",
    "######################################################################\n",
    "\n",
    "import numpy as np,pandas as pd\n",
    "import clickhouse_driver as ck\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "import time, datetime\n",
    "def print_log(logstr):\n",
    "    datetimestr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(time.time()))\n",
    "    datetimestr.strip()\n",
    "    print(\"[\", datetimestr, \"]:\", logstr)\n",
    "\n",
    "    \n",
    "######################################## 一、定义查询clickhouse方法\n",
    "def query(sql):\n",
    "    conn = ck.connect(host='172.16.92.170',port='19000',database='default',user='cp_chenjinzhao1', password='chenjinzhao1&%#7175')\n",
    "    #游动浮标\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    result=cur.fetchall()\n",
    "    return result\n",
    "\n",
    "\n",
    "######################################## 二、查两个报表的数拼接成Dataframe\n",
    "try:\n",
    "    #《企业微信》\n",
    "    sql=\"\"\"select stat_date,sum(ordernum),sum(amount) \n",
    "    from dcp_dw_rpt.t_rpt_fans_performance_lvshou_mid f \n",
    "    where substring(stat_date,1,7)=substring(toString(addDays(today(),-1)),1,7) and f.wx_channel_dep ='绿瘦商城' and f.wx_company='微雅官方' --and f.channel_1st in ('万兔','祥宸','无')\n",
    "    group by stat_date; \"\"\"\n",
    "\n",
    "    title=['日期','订单数','金额']\n",
    "    table_wx_sta=pd.DataFrame(query(sql),columns=title).sort_values('日期')\n",
    "\n",
    "    #《每日业绩及进度》\n",
    "    sql_pfm=\"\"\"select orderdate,sum(order_cnt),sum(order_cash) from dcp_dw_dmp.t_report_achievement_lvshou_new\n",
    "    where first_depart in ('商城(微信)','商城(电购)') and substring(orderdate,1,7)=substring(toString(addDays(today(),-1)),1,7) group by orderdate;\"\"\"\n",
    "\n",
    "    title=['日期','订单数','金额']\n",
    "    table_pfm_sta=pd.DataFrame(query(sql_pfm), columns = title).sort_values('日期')\n",
    "\n",
    "    #《合并计算差值》\n",
    "    table_merge = pd.merge(table_pfm_sta, table_wx_sta, how='inner', on='日期')\n",
    "    table_merge['Difference'] = table_merge['订单数_x'] - table_merge['订单数_y']\n",
    "    table_merge.index = table_merge['日期']\n",
    "    table_merge = table_merge[['订单数_x','金额_x','订单数_y','金额_y','Difference']]\n",
    "\n",
    "    sql_yesterday = \"\"\"select addDays(today(),-1); \"\"\"\n",
    "    yesterday = query(sql_yesterday)[0][0].strftime('%Y-%m-%d')\n",
    "    difference = table_merge.loc[yesterday]['Difference'] #差值用于检测、汇报\n",
    "\n",
    "    if difference!=0 :\n",
    "        msg_df = \"### 每日数据监测 \\n> #### 报表间对比：昨日《企微》的去重订单与《每日业绩》中商城订单相比少%d张\\n\"%(difference)\n",
    "    elif difference==0 :\n",
    "        msg_df = \"### 每日数据监测 \\n> #### 报表间对比：今日《企微》商城订单数与《每日业绩》无差异\\n\"\n",
    "    \n",
    "    print_log('任务一和二 报表间横向对比执行 成功')\n",
    "    time.sleep(1)\n",
    "except:\n",
    "    print_log('任务一和二 报表间横向对比执行!!! 失败\\n')\n",
    "\n",
    "    \n",
    "\n",
    "######################################## 三、查询没有渠道信息的微信号\n",
    "try:\n",
    "    sql_wx_null=r\"\"\"select stat_date,wx_id,sum(ordernum),sum(amount) \n",
    "    from dcp_dw_rpt.t_rpt_fans_performance_lvshou_mid f \n",
    "    where substring(stat_date,1,7)=substring(toString(addDays(today(),-1)),1,7) and f.wx_channel_dep is null group by stat_date,wx_id; \"\"\"\n",
    "\n",
    "    title=['日期','微信号','订单数','金额']\n",
    "    table_wx_null=pd.DataFrame(query(sql_wx_null),columns=title).sort_values('日期')\n",
    "    table_wx_null.index=table_wx_null['日期']\n",
    "    table_wx_null=table_wx_null[['微信号','订单数','金额']]\n",
    "    \n",
    "    try:\n",
    "        if len(table_wx_null.loc[yesterday].values.shape)==1:   #如果只有一个缺失渠道的微信号\n",
    "            od_cnt = table_wx_null.loc[yesterday][\"订单数\"]\n",
    "            od_amt = int(table_wx_null.loc[yesterday][\"金额\"])\n",
    "            wx_id = table_wx_null.loc[yesterday][\"微信号\"]\n",
    "        else:                                        #如果有多个缺失渠道的微信号，则需要求和该微信号的业绩 和 拼接微信号\n",
    "            od_cnt_list = table_wx_null.loc[yesterday][\"订单数\"].tolist()\n",
    "            od_amt_list = table_wx_null.loc[yesterday][\"金额\"].tolist()\n",
    "\n",
    "            od_cnt = sum(od_cnt_list)#汇总值\n",
    "            od_amt = sum(od_amt_list)#汇总值\n",
    "\n",
    "            wx_id_list = table_wx_null.loc[yesterday][\"微信号\"].tolist()\n",
    "            wx_id = ','.join(table_wx_null.loc[yesterday][\"微信号\"].tolist())\n",
    "    except KeyError: #如果没有微信号，则让缺失的订单数和业绩为0，用于后续推送的判断条件\n",
    "        wx_id = '无'\n",
    "        od_cnt = 0\n",
    "        od_amt = 0\n",
    "    \n",
    "    #定义推送文本\n",
    "    if od_cnt==0 and od_amt==0:\n",
    "        msg_wechat=\"\"\n",
    "    else:\n",
    "        msg_wechat=\"> #### %s微信号:%s没有渠道信息，其订单共%d张，业绩共%d元 \\n\"%(yesterday,wx_id,od_cnt,od_amt)\n",
    "    \n",
    "    print_log('任务三 没有渠道号的微信查询 成功')\n",
    "except:\n",
    "    print_log('任务三 没有渠道号的微信查询!!! 失败\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "######################################## 四、定义机器人的类\n",
    "#网传api使用方法\n",
    "#上传图片获得 media_ID\n",
    "import requests,json,urllib\n",
    "import time,hmac,hashlib,base64\n",
    "\n",
    "class Robot():\n",
    "    def __init__(self, appkey, appsecret, secret, webhook):\n",
    "        self.appkey = appkey\n",
    "        self.appsecret = appsecret\n",
    "        self.access_token = self.get_token()\n",
    "        self.secret = secret\n",
    "        self.webhook = webhook\n",
    "        self.url = self.get_url()\n",
    "    \n",
    "    def get_token(self): # 获取token\n",
    "        params = {\"appkey\": self.appkey,\"appsecret\": self.appsecret}\n",
    "        response = requests.get(\"https://oapi.dingtalk.com/gettoken\", params=params)\n",
    "        return response.json().get(\"access_token\")\n",
    "    \n",
    "    def get_url(self): #获得秘钥\n",
    "        timestamp = int(round(time.time() * 1000))\n",
    "        \n",
    "        secret_enc = bytes(self.secret, encoding='utf-8')#.encode('utf-8')\n",
    "        string_to_sign = '{}\\n{}'.format(timestamp, self.secret)\n",
    "        string_to_sign_enc = bytes(string_to_sign, encoding='utf-8')\n",
    "        hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()\n",
    "\n",
    "        sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))\n",
    "     #测试群链接配置\n",
    "        return self.webhook+\"&timestamp=\"+str(timestamp)+'&sign='+sign\n",
    "\n",
    "    def send_msg(self,msg): #发送消息\n",
    "        header = {\"Content-Type\": \"application/json\",\"Charset\": \"UTF-8\"}\n",
    "        data = {\"msgtype\": 'text' , 'text': {'content':msg}}  \n",
    "        sendData = json.dumps(data).encode(\"utf-8\")  # 对请求的数据进行json封装\n",
    "\n",
    "        request = urllib.request.Request(url=self.url, data=sendData, headers=header) #发送请求\n",
    "        opener = urllib.request.urlopen(request,timeout=10) # 将请求发回的数据构建成为文件格式\n",
    "        return json.load(opener)\n",
    "\n",
    "    def upload_media(self,file_path):\n",
    "        header = {\"Content-Type\": \"application/json\",\"Charset\": \"UTF-8\"}\n",
    "        upload_url='https://oapi.dingtalk.com/media/upload?access_token='+self.access_token+'&type=image'\n",
    "    #构建data字典(请求数据)\n",
    "        files = {'media': open(file_path, 'rb')}\n",
    "        data = {'access_token': self.access_token,'type': 'image'}\n",
    "    #向带有access_token的url发送post请求，携带data和file参数\n",
    "        response = requests.post(upload_url, files=files, data=data)\n",
    "        return response.json()['media_id']\n",
    "    \n",
    "    def send_markdown(self,content):#发送markdown\n",
    "        header = {\"Content-Type\": \"application/json\",\"Charset\": \"UTF-8\"}\n",
    "    #构建data字典(请求数据)，发送post请求\n",
    "        data = {\"msgtype\":'markdown' , 'markdown':content}\n",
    "        sendData = json.dumps(data).encode(\"utf-8\")  # 对请求的数据进行json封装\n",
    "    #向带有access_token的url发送post请求，携带data和file参数\n",
    "        request = urllib.request.Request(url=self.url, data=sendData, headers=header) #发送请求\n",
    "        opener = urllib.request.urlopen(request,timeout=10) # 将请求发回的数据构建成为文件格式\n",
    "        return json.load(opener)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    appkey = \"dinggusun3wou6cp1eev\"\n",
    "    appsecret = \"iTYs60fL6G7s_7N5ac4e6wCgDY9_w2X-gWWdJEGYRR9kI3QTC095rGJcbv-J3xn0\"\n",
    "    secret = ''\n",
    "    webhook = ''\n",
    "    \n",
    "    \n",
    "######################################## 五、定义机器人实例，并上传图片\n",
    "try:\n",
    "    secret='SEC52e872ea0f8203dd964927d7c05421bd00b694d3cac0a131127b84310e02a127'#FR测试群\n",
    "    webhook=\"https://oapi.dingtalk.com/robot/send?access_token=cd7925e3d8df74289a4651e6ec9c887921d9558d682f5fd2baf29d13ac7cc01d\"\n",
    "    \n",
    "#     secret='SEC7e55c873c5f418c963ee132000652b17a31971e5e385a577a050ec24c9718466'#数据观察群\n",
    "#     webhook=\"https://oapi.dingtalk.com/robot/send?access_token=85abf9287c8e8155b9af2d5c030a69badf3fcaf126b363b5d9a311b043f2d1ca\"\n",
    "    #从机器人配置页面获取secret和webhook，计算sign并加入到到url，定义成机器人属性。\n",
    "\n",
    "    robot_test = Robot(appkey,appsecret,secret=secret,webhook=webhook)\n",
    "\n",
    "    #上传图片\n",
    "    image=r'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!7eff!!7626!!5546!!57ce!!2f!!4f01!!4e1a!!5fae!!4fe1!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!!2f!!5546!!57ce!!28!!4f01!!4e1a!!5fae!!4fe1!!29!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=image'\n",
    "    response=urllib.request.urlopen(image,timeout=10)\n",
    "    picture=response.read()\n",
    "    with open(r\"/opt/jupyter-notebook/DingdingPush/wechat_sta.jpg\",'wb') as f:\n",
    "        f.write(picture)\n",
    "        \n",
    "    media_id = robot_test.upload_media('/opt/jupyter-notebook/DingdingPush/wechat_sta.jpg')\n",
    "    \n",
    "    print_log('任务四和五 定义机器人和上传图片 成功')\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print_log('任务四和五 定义机器人和上传图片!!! 失败\\n')  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-11-12 22:27:44 ]: 任务六 日波动幅度计算 成功\n",
      "[ 2020-11-12 22:27:51 ]: 任务七 历史数据对比 成功\n"
     ]
    }
   ],
   "source": [
    "######################################## 六、先计算波动，定义msg_vibration\n",
    "def cal_vibration(series):\n",
    "    vibration = []\n",
    "    for i,j in zip(series,range(len(series))):\n",
    "        if i<50 or j==0 :                         #1号或者节假日则令增幅为0\n",
    "            vibration.append(0)\n",
    "        else:\n",
    "            vb = (i-series[j-1])/series[j-1]\n",
    "            vibration.append( round(vb,4) )        #增幅\n",
    "    return vibration                              #输出list\n",
    "\n",
    "try:\n",
    "    #判断波动大于50%的字段\n",
    "    table_merge['Vibration']=cal_vibration(table_merge.loc[:,'金额_y']) #企微的金额\n",
    "    table_merge\n",
    "\n",
    "    day_of_yesterday = time.strftime('%w', time.strptime(yesterday,'%Y-%m-%d') )   #昨天周几，用于以下逻辑判断\n",
    "    vb_ytd = table_merge.loc[yesterday,'Vibration']                                #昨天波动，用于以下逻辑判断和推送语句\n",
    "    pfm_ytd = table_merge.loc[yesterday,'金额_y']  \n",
    "\n",
    "    if day_of_yesterday==0 and abs(vb_ytd)>=0.25 and pfm_ytd > 300 :   #周日，非国家节假日，波幅大于20%\n",
    "        msg_vibration = \"\"\"> #### 环比：%s周日，《企微》下单金额增长%s，环比增幅大于%s \\n\"\"\"%(yesterday,str(round(vb_ytd*100,2))+\"%\",'25%')\n",
    "    elif abs(vb_ytd)>=0.15 and pfm_ytd > 300:                          #非国家节假日，波幅大于10%\n",
    "        msg_vibration = \"\"\"> #### 环比：昨日《企微》商城下单金额增长%s，环比增幅大于%s \\n\"\"\"%(str(round(vb_ytd*100,2))+\"%\",'15%')\n",
    "    else:\n",
    "        msg_vibration= \"\"\n",
    "    \n",
    "    print_log('任务六 日波动幅度计算 成功')\n",
    "except:\n",
    "    print_log('任务六 日波动幅度计算!!! 失败\\n')\n",
    "    \n",
    "    \n",
    "######################################## 七、历史数据对比\n",
    "\n",
    "################### 7.1.定义方法：读取文档、核对新旧表格、存档并计算变化率\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#7.1.1.输入文件地址、跳过的行数、字段名称、读取行数，以读出存放在指定位置的Excel文档\n",
    "def read_table(direction, skiprows, names, days): \n",
    "    table = pd.read_excel(direction, sheet_name=1, skiprows=skiprows, names=names, index_col='日期')\n",
    "    \n",
    "    return table.head(days) \n",
    "\n",
    "#7.1.2.输入今天的数据表格和昨天的数据表格做对比，加上字段名（用于中间处理），输出两表相减的表格\n",
    "def table_his_check(table_ytd, table_dbytd, names, days): \n",
    "    table_check = pd.merge(table_ytd,table_dbytd,on='日期')\n",
    "    for i in names[1:]:\n",
    "        table_check[i] = table_check[i+'_x']-table_check[i+'_y']\n",
    "        table_check.pop(i+'_x')\n",
    "        table_check.pop(i+'_y')\n",
    "    return table_check.head(days-1)#如《企微》会出现当天数据，剔除当天数据\n",
    "\n",
    "#7.1.3.输入推送的url 和 读取昨日数据表格的参数\n",
    "#      输出①：昨日数据 减 前日数据的核对表，②：昨天表格每个字段的总和\n",
    "def final_check(url,filename,skiprows,names):\n",
    "    #拼接今天和昨天下载的两个文件路径\n",
    "    td_fname = time.strftime(\"%Y_%m_%d_\")\n",
    "    ytd_fname = datetime.datetime.strftime(datetime.datetime.now()+ relativedelta(days=-1) ,\"%Y_%m_%d_\") \n",
    "    dr_td = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + td_fname + filename\n",
    "    dr_ytd = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + ytd_fname + filename\n",
    "    \n",
    "    #计算days参数取值：若今天是1号 则计算上个月有多少天，否则按今天日期减1\n",
    "    import calendar\n",
    "    if int(time.strftime(\"%d\"))==1:\n",
    "        days = calendar.monthrange(int(time.strftime(\"%y\")),int(time.strftime(\"%m\"))-1)\n",
    "    else:\n",
    "        days = int(time.strftime(\"%d\"))-1\n",
    "    \n",
    "    #读取昨天《每日业绩》数据\n",
    "    dbytd = read_table(dr_ytd, skiprows, names, days)\n",
    "\n",
    "    #先存档今日《每日业绩》数据，再重新读取\n",
    "    response = urllib.request.urlopen(url)\n",
    "    excel = response.read()\n",
    "    with open(dr_td,'wb') as f:\n",
    "        f.write(excel)    \n",
    "    ytd = read_table(dr_td, skiprows, names, days) \n",
    "\n",
    "    return table_his_check(ytd, dbytd, names, days) , dbytd.sum()\n",
    "\n",
    "################### 7.2.开始计算核对表格\n",
    "try:\n",
    "    ### 7.2.1.《每日业绩》核对历史数据\n",
    "    ### 7.2.1.1.根据表格特征定义read_table()的参数\n",
    "    skiprows_pfm = [0,1,3]\n",
    "    columns_pfm=['日期','商城单数','商城业绩','事业一部业绩','事业二部业绩','事业三部业绩','事业五部业绩','事业六部业绩','事业八部业绩'\n",
    "             ,'湖北业绩','D28业绩','体管业绩总计','电商业绩','业绩总计','APP商城']\n",
    "    url_pfm = 'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!9500!!552e!!7ba1!!7406!!90e8!!2f!!ff08!!96c6!!56e2!!ff09!!4e1a!!52a1!!7cfb!!4e0b!!5355!!4e1a!!7ee9!!53ca!!8fdb!!5ea6!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=excel'\n",
    "\n",
    "    ### 7.2.1.2.获取核对表和对照表字段总和\n",
    "    check_pfm,dbytd_sum  = final_check(url_pfm,\"daily_pfm.xlsx\",skiprows_pfm,columns_pfm)\n",
    "\n",
    "    ### 7.2.1.3.计算每个字段变化的差距/本月总业绩的总和\n",
    "    alter_series_pfm = abs(check_pfm.sum()/dbytd_sum)*100\n",
    "\n",
    "    ### 7.2.1.4.计算平均波动率\n",
    "    alter_ratio_pfm = np.mean(alter_series_pfm)\n",
    "    alter_ratio_pfm_str = str(round(alter_ratio_pfm,2))+'%'     #文本用于推送\n",
    "\n",
    "    ### 7.2.1.5.取出变化比率高于均值的字段 和 对应值\n",
    "    alt_pfm = check_pfm.sum()\n",
    "    major_alt_pfm = '商城业绩' + str(int(alt_pfm['商城业绩'])) +',体管业绩' + str(int(alt_pfm['体管业绩总计']))\n",
    "\n",
    "    ### 7.2.1.6.拼接文本信息\n",
    "    msg_alter_pfm = \"> 历史数据对比：《每日业绩》历史数据平均变动%s，主要变化如下：%s \\n\"%(alter_ratio_pfm_str, major_alt)\n",
    "    \n",
    "    \n",
    "    ### 7.2.2.《企微》核对历史数据，目前仅用于保存文件\n",
    "    columns_wx=['日期','总进粉','被删粉','被删率','实际粉','有效粉','成交数','成交额','总进粉成交率','实际粉成交率','有效粉成交率','单均'\n",
    "              ,'资源产出','A类','B类','C类','D类','解封','广告','疾病禁售','16岁以下','无效占比']\n",
    "    skiprows_wx = [0,1]\n",
    "    url_wx = 'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!7eff!!7626!!5546!!57ce!!2f!!4f01!!4e1a!!5fae!!4fe1!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!!2f!!5546!!57ce!!28!!4f01!!4e1a!!5fae!!4fe1!!29!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=excel'\n",
    "\n",
    "    check_wx,alt_series_wx = final_check(url_wx,'wx_pfm.xlsx',skiprows_wx,columns_wx) \n",
    "    \n",
    "    ### 7.2.2.2.计算每个字段变化的差距/本月总业绩的总和\n",
    "    alter_series_wx = abs(check_wx.sum()/alt_series_wx)*100\n",
    "\n",
    "    ### 7.2.2.3.计算平均波动率\n",
    "    alter_ratio_wx = np.mean(alter_series_wx)\n",
    "    alter_ratio_wx_str = str(round(alter_ratio_wx,2))+'%'     #文本用于推送\n",
    "\n",
    "    ### 7.2.2.4.主要的字段及其变化\n",
    "    alt_wx = check_wx.sum()\n",
    "    major_alt_wx = '总进粉' + str(int(alt_wx['总进粉']))+',成交数' + str(int(alt_wx['成交数']))\n",
    "\n",
    "    ### 7.2.2.5.拼接文本信息\n",
    "    msg_alter_wx = \"> 历史数据对比：《企业微信》历史数据平均变动%s，主要变化如下：%s \\n\"%(alter_ratio_pfm_str, major_alt)\n",
    "    \n",
    "    \n",
    "    print_log('任务七 历史数据对比 成功')\n",
    "except:\n",
    "    print_log('任务七 历史数据对比!!! 失败\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#7.1.1.输入文件地址、跳过的行数、字段名称、读取行数，以读出存放在指定位置的Excel文档\n",
    "def read_table(direction, skiprows, names, days): \n",
    "    table = pd.read_excel(direction, sheet_name=1, skiprows=skiprows, names=names, index_col='日期')\n",
    "    \n",
    "    return table.head(days) \n",
    "\n",
    "#7.1.2.输入今天的数据表格和昨天的数据表格做对比，加上字段名（用于中间处理），输出两表相减的表格\n",
    "def table_his_check(table_ytd, table_dbytd, names, days): \n",
    "    table_check = pd.merge(table_ytd,table_dbytd,on='日期')\n",
    "    for i in names[1:]:\n",
    "        table_check[i] = table_check[i+'_x']-table_check[i+'_y']\n",
    "        table_check.pop(i+'_x')\n",
    "        table_check.pop(i+'_y')\n",
    "    return table_check.head(days-1)#如《企微》会出现当天数据，剔除当天数据\n",
    "\n",
    "#7.1.3.输入推送的url 和 读取昨日数据表格的参数\n",
    "#      输出①：昨日数据 减 前日数据的核对表，②：昨天表格每个字段的总和\n",
    "def final_check(url,filename,skiprows,names):\n",
    "    #拼接今天和昨天下载的两个文件路径\n",
    "    td_fname = time.strftime(\"%Y_%m_%d_\")\n",
    "    ytd_fname = datetime.datetime.strftime(datetime.datetime.now()+ relativedelta(days=-1) ,\"%Y_%m_%d_\") \n",
    "    dr_td = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + td_fname + filename\n",
    "    dr_ytd = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + ytd_fname + filename\n",
    "    \n",
    "    #计算days参数取值：若今天是1号 则计算上个月有多少天，否则按今天日期减1\n",
    "    import calendar\n",
    "    if int(time.strftime(\"%d\"))==1:\n",
    "        days = calendar.monthrange(int(time.strftime(\"%y\")),int(time.strftime(\"%m\"))-1)\n",
    "    else:\n",
    "        days = int(time.strftime(\"%d\"))-1\n",
    "    \n",
    "    #读取昨天《每日业绩》数据\n",
    "    dbytd = read_table(dr_ytd, skiprows, names, days)\n",
    "\n",
    "    #先存档今日《每日业绩》数据，再重新读取\n",
    "    response = urllib.request.urlopen(url)\n",
    "    excel = response.read()\n",
    "    with open(dr_td,'wb') as f:\n",
    "        f.write(excel)    \n",
    "    ytd = read_table(dr_td, skiprows, names, days) \n",
    "\n",
    "    return table_his_check(ytd, dbytd, names, days) , dbytd.sum()\n",
    "\n",
    "\n",
    "    ### 7.2.1.《每日业绩》核对历史数据\n",
    "    ### 7.2.1.1.根据表格特征定义read_table()的参数\n",
    "    skiprows_pfm = [0,1,3]\n",
    "    columns_pfm=['日期','商城单数','商城业绩','事业一部业绩','事业二部业绩','事业三部业绩','事业五部业绩','事业六部业绩','事业八部业绩'\n",
    "             ,'湖北业绩','D28业绩','体管业绩总计','电商业绩','业绩总计','APP商城']\n",
    "    url_pfm = 'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!9500!!552e!!7ba1!!7406!!90e8!!2f!!ff08!!96c6!!56e2!!ff09!!4e1a!!52a1!!7cfb!!4e0b!!5355!!4e1a!!7ee9!!53ca!!8fdb!!5ea6!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=excel'\n",
    "\n",
    "    ### 7.2.1.2.获取核对表和对照表字段总和\n",
    "    check_pfm,dbytd_sum  = final_check(url_pfm,\"daily_pfm.xlsx\",skiprows_pfm,columns_pfm)\n",
    "\n",
    "    ### 7.2.1.3.计算每个字段变化的差距/本月总业绩的总和\n",
    "    alter_series_pfm = abs(check_pfm.sum()/dbytd_sum)*100\n",
    "\n",
    "    ### 7.2.1.4.计算平均波动率\n",
    "    alter_ratio_pfm = np.mean(alter_series_pfm)\n",
    "    alter_ratio_pfm_str = str(round(alter_ratio_pfm,2))+'%'     #文本用于推送\n",
    "\n",
    "    ### 7.2.1.5.取出变化比率高于均值的字段 和 对应值\n",
    "    alt_pfm = check_pfm.sum()\n",
    "    major_alt_pfm = '商城业绩' + str(int(alt_pfm['商城业绩'])) +',体管业绩' + str(int(alt_pfm['体管业绩总计']))\n",
    "\n",
    "    ### 7.2.1.6.拼接文本信息\n",
    "    msg_alter_pfm = \"> 历史数据对比：《每日业绩》历史数据平均变动%s，主要变化如下：%s \\n\"%(alter_ratio_pfm_str, major_alt)\n",
    "    \n",
    "    \n",
    "    ### 7.2.2.《企微》核对历史数据，目前仅用于保存文件\n",
    "    columns_wx=['日期','总进粉','被删粉','被删率','实际粉','有效粉','成交数','成交额','总进粉成交率','实际粉成交率','有效粉成交率','单均'\n",
    "              ,'资源产出','A类','B类','C类','D类','解封','广告','疾病禁售','16岁以下','无效占比']\n",
    "    skiprows_wx = [0,1]\n",
    "    url_wx = 'http://172.16.92.9:28080/bi/Viewer?au_act=login&proc=1&action=viewer&hback=true&db=!7eff!!7626!!5546!!57ce!!2f!!4f01!!4e1a!!5fae!!4fe1!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!!2f!!5546!!57ce!!28!!4f01!!4e1a!!5fae!!4fe1!!29!!6bcf!!65e5!!4e1a!!7ee9!!62a5!!8868!.db&isAir=false&isFav=false&adminv=dingdingpush&passv=DingdingPush_LS2019&export=excel'\n",
    "\n",
    "    check_wx,alt_series_wx = final_check(url_wx,'wx_pfm.xlsx',skiprows_wx,columns_wx) \n",
    "    \n",
    "    ### 7.2.2.2.计算每个字段变化的差距/本月总业绩的总和\n",
    "    alter_series_wx = abs(check_wx.sum()/alt_series_wx)*100\n",
    "\n",
    "    ### 7.2.2.3.计算平均波动率\n",
    "    alter_ratio_wx = np.mean(alter_series_wx)\n",
    "    alter_ratio_wx_str = str(round(alter_ratio_wx,2))+'%'     #文本用于推送\n",
    "\n",
    "    ### 7.2.2.4.主要的字段及其变化\n",
    "    alt_wx = check_wx.sum()\n",
    "    major_alt_wx = '总进粉' + str(int(alt_wx['总进粉']))+',成交数' + str(int(alt_wx['成交数']))\n",
    "\n",
    "    ### 7.2.2.5.拼接文本信息\n",
    "    msg_alter_wx = \"> 历史数据对比：《企业微信》历史数据平均变动%s，主要变化如下：%s \\n\"%(alter_ratio_pfm_str, major_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#优化\n",
    "#1.拆分任务7，理顺逻辑 增强代码健壮性\n",
    "#2.思考python实现和永洪推送的差异性：可以得到历史数据波动，灵活计算今日增幅\n",
    "\n",
    "##3.有bug：微信号没有应该展示点什么\n",
    "#2020-11-08微信号:没有渠道信息，其订单共1张，业绩共320元  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-11-12 17:34:31 ]: 任务八 Markdown发送 成功\n"
     ]
    }
   ],
   "source": [
    "######################################## 八、拼接完整msg，发送Markdown\n",
    "try:\n",
    "    pic = \"> ![screenshot](%s) \\n\"%(media_id)\n",
    "    \n",
    "    # 二、msg_df   三、msg_wechat   7.2.1.6.msg_alter     六、msg_vibration\n",
    "    msg = msg_df + pic + msg_wechat +  msg_alter_wx + msg_vibration\n",
    "    \n",
    "    robot_test.send_markdown(content={\"text\": msg, \"title\": \"Data Validation\"} )    \n",
    "\n",
    "    print_log('任务八 Markdown发送 成功')\n",
    "except:\n",
    "    print_log('任务八 Markdown发送!!! 失败\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-11-09 10:07:38 ]: 任务九 合并文件 成功\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################## 九、每周一合并一次文件\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "try:\n",
    "    if time.strftime(\"%w\")=='1':\n",
    "        #写入一个_all结尾的文件，循环结束后执行\n",
    "        writer_wx = pd.ExcelWriter(time.strftime(\"%Y_%m_%d_\")+\"wx_pfm_all.xlsx\")\n",
    "        writer_pfm = pd.ExcelWriter(time.strftime(\"%Y_%m_%d_\")+\"daily_pfm_all.xlsx\")\n",
    "\n",
    "        for i in range(7):\n",
    "            #计算日期day，用于拼接文件名\n",
    "            \n",
    "            day = datetime.datetime.strftime(datetime.datetime.now().date() + relativedelta(days=-1-i) ,\"%Y_%m_%d_\")\n",
    "            dr_wx = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + day + \"wx_pfm.xlsx\"\n",
    "            dr_pfm = '/opt/jupyter-notebook/DingdingPush/Data_Validation/' + day + \"daily_pfm.xlsx\"\n",
    "\n",
    "            #计算读取的行数days\n",
    "            if int(time.strftime(\"%d\"))==1:\n",
    "                days = calendar.monthrange(int(time.strftime(\"%y\")),int(time.strftime(\"%m\"))-1)[1]\n",
    "            else:\n",
    "                days = int(day[8:10])-1\n",
    "\n",
    "            #读取表格，定义to_excel，循环结束后执行    \n",
    "            excel_wx = read_table(dr_wx, skiprows_wx, columns_wx, days)\n",
    "            excel_pfm = read_table(dr_pfm, skiprows_pfm, columns_pfm, days)\n",
    "\n",
    "            excel_wx.to_excel(writer_wx,day) #页面以\"%Y_%m_%d_\"格式展示\n",
    "            excel_pfm.to_excel(writer_pfm,day) #页面以\"%Y_%m_%d_\"格式展示\n",
    "\n",
    "            os.remove(dr_wx)\n",
    "            os.remove(dr_pfm)\n",
    "\n",
    "        writer_wx.save()\n",
    "        writer_pfm.save()\n",
    "\n",
    "    print_log('任务九 合并文件 成功\\n\\n')\n",
    "except:\n",
    "    print_log('任务九 合并文件!!! 失败\\n\\n') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
